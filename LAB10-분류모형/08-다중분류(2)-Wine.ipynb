{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LAB09] 지도학습 > 분류 > 08-다중분류(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #01. 준비작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 패키지 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 기본 참조\n",
    "from hossam import *\n",
    "from pandas import DataFrame, concat\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 분류모형 (대표모형 하나만 지정)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 불균형 데이터 처리\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "\n",
    "# 로지스틱 성능평가 함수\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 필요한 함수\n",
    "\n",
    "- hs_describe()\n",
    "- hs_category_describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = load_data('wine_dataset')\n",
    "origin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] 명목형에 대한 타입 변환\n",
    "\n",
    "데이터 품질 확인을 위해서는 타입 변환이 수행되어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = origin.copy()\n",
    "df1['class'] = df1['class'].astype('category')\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #02. 데이터 품질 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 연속형 변수 품질 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = hs_describe(df1)\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 결측치는 없으나, 약간의 이상치가 발견된다. 로그 변환을 통해 이상치를 완화할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 로그변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = desc[desc['log_need'] != '낮음'].index.tolist()\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "\n",
    "for col in fields:\n",
    "    df2[col] = np.log1p(df2[col])\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] 명목형 변수(종속변수) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = hs_category_describe(df2)\n",
    "display(a)\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 클래스간 비율에 큰 차이를 보이지 않는다. 데이터 증강이 필요 없을것으로 보인다. 하지만 데이터 증강후 결과를 비교해 볼 필요는 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #03. 분류모형 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yname = \"class\"\n",
    "x = df2.drop(columns=[yname])\n",
    "y = df2[yname]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,\n",
    "                                                      random_state=52)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 학습모델 구성\n",
    "\n",
    "실습 시간을 고려하여 RandomForest 모델에 대해서만 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\n",
    "        \"model\",\n",
    "        RandomForestClassifier(\n",
    "            random_state=52,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    ),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [300, 500],\n",
    "    \"model__max_depth\": [None, 10],\n",
    "    \"model__min_samples_leaf\": [5, 10],\n",
    "    \"model__max_features\": [\"sqrt\", 1.0],\n",
    "    \"model__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"model__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "\n",
    "estimator = gs.best_estimator_\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #04. 성능평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 다중분류 성능평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hs_cls_multi_scores(estimator, x_test, y_test):\n",
    "    #-----------------------------\n",
    "    # 입력값 정리\n",
    "    #-----------------------------\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    y_proba = estimator.predict_proba(x_test)\n",
    "    classes = np.unique(y_test)\n",
    "\n",
    "    #-----------------------------\n",
    "    # 이항분류와 동일하게 사용가능한 지표\n",
    "    #-----------------------------\n",
    "    score_df = DataFrame({\n",
    "        \"accuracy\": [accuracy_score(y_test, y_pred)],\n",
    "        \"precision\": [precision_score(y_test, y_pred, average=\"macro\", zero_division=0)],\n",
    "        \"recall\": [recall_score(y_test, y_pred, average=\"macro\", zero_division=0)],\n",
    "        \"f1\": [f1_score(y_test, y_pred, average=\"macro\", zero_division=0)],\n",
    "    })\n",
    "\n",
    "    #-----------------------------\n",
    "    # 다중분류 전용 지표 (OvR)\n",
    "    #-----------------------------\n",
    "    fpr_list = []\n",
    "    tnr_list = []\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        # 해당 클래스 vs 나머지\n",
    "        y_true_binary = (y_test == cls).astype(int)\n",
    "        y_pred_binary = (y_pred == cls).astype(int)\n",
    "\n",
    "        cm = confusion_matrix(y_true_binary, y_pred_binary, labels=[0, 1])\n",
    "        TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "        fpr = FP / (FP + TN) if (FP + TN) > 0 else np.nan\n",
    "        tnr = TN / (FP + TN) if (FP + TN) > 0 else np.nan\n",
    "\n",
    "        fpr_list.append(fpr)\n",
    "        tnr_list.append(tnr)\n",
    "\n",
    "    score_df[\"FPR (macro)\"] = np.nanmean(fpr_list)\n",
    "    score_df[\"TNR (macro)\"] = np.nanmean(tnr_list)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 다중 AUC (OvR 방식)\n",
    "    # -----------------------------\n",
    "    score_df[\"AUC (macro, OvR)\"] = roc_auc_score(\n",
    "        y_test,\n",
    "        y_proba,\n",
    "        multi_class=\"ovr\",\n",
    "        average=\"macro\"\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 시각화\n",
    "    # -----------------------------\n",
    "    # y_test를 1차원 배열로 변환\n",
    "    y_test_array = np.asarray(y_test).ravel()\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        # 해당 클래스 vs 나머지\n",
    "        y_true_binary = (y_test_array == cls).astype(int)\n",
    "        y_score = y_proba[:, i]\n",
    "\n",
    "        # ROC 계산\n",
    "        fpr, tpr, thresholds = roc_curve(y_true_binary, y_score)\n",
    "        auc_score = roc_auc_score(y_true_binary, y_score)\n",
    "\n",
    "        # -----------------------------\n",
    "        # 그래프 (클래스별 하나씩)\n",
    "        # -----------------------------\n",
    "        fig, ax = plt.subplots(1, 1, dpi=100, figsize=(480/100, 480/100))\n",
    "        sb.lineplot(x=fpr, y=tpr)\n",
    "        sb.lineplot(x=[0, 1], y=[0, 1], linestyle=\"--\")\n",
    "        ax.set_xlabel(\"False Positive Rate\", fontsize=9)\n",
    "        ax.set_ylabel(\"True Positive Rate\", fontsize=9)\n",
    "        ax.set_title(f\"ROC Curve - Class {cls} (AUC={auc_score:.4f})\", fontsize=10)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    # -----------------------------\n",
    "    # 결과리턴\n",
    "    # -----------------------------\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = hs_cls_multi_scores(estimator, x_test, y_test)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #05. 데이터 증강 후 결과 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] 데이터 증강 모델 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pipe = imbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('sm', SMOTE(random_state=52, k_neighbors=5)),\n",
    "    ('model', RandomForestClassifier(random_state=52, n_jobs=-1))\n",
    "])\n",
    "\n",
    "sm_param_grid = {\n",
    "    \"model__n_estimators\": [300, 500],\n",
    "    \"model__max_depth\": [None, 10],\n",
    "    \"model__min_samples_leaf\": [5, 10],\n",
    "    \"model__max_features\": [\"sqrt\", 1.0],\n",
    "    \"model__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"model__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "sm_gs = GridSearchCV(\n",
    "    estimator=sm_pipe,\n",
    "    param_grid=sm_param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "sm_gs.fit(x_train, y_train)\n",
    "\n",
    "rf_cls_estimator = sm_gs.best_estimator_\n",
    "\n",
    "sm_score_df = hs_cls_multi_scores(\n",
    "    rf_cls_estimator,\n",
    "    x_test,\n",
    "    y_test\n",
    ")\n",
    "\n",
    "rdf = concat([score_df, sm_score_df], axis=0)\n",
    "rdf.index = ['기본', 'SMOTE']\n",
    "rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 처음 예측했던바와 같이 데이터 불균형이 심하지 않은 데이터이므로 데이터 증강의 효과는 없다.\n",
    "\n",
    "### 참고 - 로그변환을 수행하지 않은 경우의 결과\n",
    "\n",
    "| | accuracy | precision | recall | f1 | FPR (macro) | TNR (macro) | AUC (macro, OvR) |\n",
    "|---|---|---|---|---|---|---|---|\n",
    "| 기본 | 0.978 | 0.972 | 0.982 | 0.976 | 0.010 | 0.990 | 0.997 |\n",
    "| SMOTE | 0.978 | 0.972 | 0.982 | 0.976 | 0.010 | 0.990 | 0.997 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
